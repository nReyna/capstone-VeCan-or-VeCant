{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy   as np\n",
    "import pandas  as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing   import scale, StandardScaler\n",
    "from sklearn.decomposition   import PCA, TruncatedSVD\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_pred_words(kmObj, X_df, ftrs_list, pred, num_reviews=5, num_words=5): \n",
    "    '''\n",
    "        kmObjn: a kmeans object\n",
    "        gTrue: true categories (ground truth)\n",
    "    '''\n",
    "    \n",
    "    num_words += 1\n",
    "    numClusters = kmObj.get_params()['n_clusters']\n",
    "    \n",
    "    for i in range(numClusters):\n",
    "        mask = (pred == i)\n",
    "        \n",
    "        rev_ind = [ind for ind, flag in enumerate(mask) if flag]\n",
    "        \n",
    "        sample_reviews = np.random.choice(rev_ind, num_reviews, replace=False)\n",
    "        \n",
    "        print(\"\\nCluster \", i, \" =====\")\n",
    "        for review in sample_reviews:\n",
    "            indx = X_df[review,:].indices\n",
    "            data = X_df[review,:].data\n",
    "            \n",
    "            termsVals = indx[data.argsort()][-1:-num_words:-1]\n",
    "            \n",
    "            terms = []\n",
    "            for w in termsVals:\n",
    "                terms.append(ftrs_list[w])\n",
    "            print(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_top_words(kmeans_model, svd_model, ftrs, num_words=10):\n",
    "    '''\n",
    "        Print out the top num_words for each of the centroids in the kmeans model, \n",
    "        after we return the centroids back in 'word space' using the inverse SVD \n",
    "        transformation\n",
    "        \n",
    "        input:\n",
    "        kmeans_model -  kmeans model object\n",
    "        svd_model - svd model object\n",
    "        ftrs - the features from the TFIDF vectorizer\n",
    "        num_words - number of words to display        \n",
    "    '''\n",
    "        \n",
    "    num_words += 1\n",
    "    \n",
    "    ftrs_array = np.array(ftrs)\n",
    "\n",
    "    centroids = svd_model.inverse_transform(kmeans_model.cluster_centers_)\n",
    "\n",
    "    for c in centroids:\n",
    "        ind = np.abs(c).argsort()\n",
    "        ind = ind[-1:-num_words:-1]\n",
    "        print(ftrs_array[ind], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catPred(kmObj, gTrue, pred): \n",
    "    '''\n",
    "        kmObjn: a kmeans object\n",
    "        gTrue: true categories (ground truth)\n",
    "    '''\n",
    "    numClusters = kmObj.get_params()['n_clusters']\n",
    "        \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=numClusters, sharey=True, figsize=(50,12))\n",
    "\n",
    "    for i in range(numClusters):\n",
    "        mask = (pred == i)\n",
    "        val = np.unique( gTrue[mask], return_counts=True)\n",
    "        lbl = val[0]\n",
    "        ht  = val[1] / val[1].sum()\n",
    "        ax[i].bar(range(len(lbl)), height=ht, tick_label = lbl)\n",
    "        ax[i].set_xticklabels(lbl, fontsize=20)\n",
    "        ax[i].set_title(i, fontsize=20)\n",
    "\n",
    "        ax[0].set_yticklabels([\"0\", \"0.2\", \"0.4\", \"0.6\", \"0.8\"], fontsize=20)\n",
    "        ax[0].set_ylabel(\"Proportion\", fontsize = 32);\n",
    "        plt.suptitle(\"Proportion of Categories in each Clusterc\", fontsize = 32);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Load Pickled Dataset - Cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Five Cuisines for US (data) states only \n",
    "# - tying to minimize the amount of reviews using a foriegn language\n",
    "\n",
    "df = pd.read_pickle('fiveCuisine.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = df.drop('category', axis=1)\n",
    "y_df = df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['category'].value_counts().values\n",
    "lbls = list(df['category'].value_counts().index)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.bar(range(len(x)), height=x, tick_label = lbls);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Manipulate data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize Review Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use regex operations to remove numbers (dimension) from vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# create a term transformer object\n",
    "termTrans = vectorizer.fit(X_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_term  = termTrans.transform(X_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( X_train_term.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather features USED for vetorization\n",
    "ftrs = m_termTrans.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Reduce Dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=100, n_iter=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_svd = svd.fit_transform(X_train_term)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = svd.singular_values_\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i+1 for i in range(len(s))]\n",
    "plt.plot(x, s, marker='o')\n",
    "plt.xlabel(\"Singular Values\")\n",
    "plt.ylabel(\"Value\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vExp = m_svd.explained_variance_ratio_.sum()*100\n",
    "print('Variance Explained: ', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "\n",
    "### Apply predictive model to data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.fit(X_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pred_words(kmeans, X_train_term, ftrs, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catPred(kmeans, y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pred_words(kmeans, X_test_term, ftrs, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_top_words(kmeans, svd, ftrs, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
